{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "root_dir = os.path.abspath(os.path.join(notebook_dir, \"../../\"))\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from service import EnvironmentSecretService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.exchange import ExchangeType\n",
    "from core.models.lookback import Lookback\n",
    "from core.models.timeframe import Timeframe\n",
    "from exchange import ExchangeFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_EXCHANGE = ExchangeType.BYBIT\n",
    "DEFAULT_TIMEFRAME = Timeframe.ONE_HOUR\n",
    "DEFAULT_LOOKBACK = Lookback.SIX_MONTH\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "emb_filename = f'ocean_emb_{datetime.now().strftime('%Y-%m-%d')}.npy'\n",
    "volume_df_filename = f'ocean_ft_{datetime.now().strftime('%Y-%m-%d')}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_factory = ExchangeFactory(EnvironmentSecretService())\n",
    "exchange = exchange_factory.create(DEFAULT_EXCHANGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = exchange.fetch_future_symbols()\n",
    "\n",
    "data = []\n",
    "for symbol in symbols:\n",
    "    for ohlcv in exchange.fetch_ohlcv(symbol, DEFAULT_TIMEFRAME, DEFAULT_LOOKBACK):\n",
    "        _timestamp, _open, _high, _low, _close, _volume = ohlcv\n",
    "        data.append([symbol.name, _timestamp, _open, _high, _low, _close, _volume])\n",
    "\n",
    "symbols_df = pd.DataFrame(data, columns=['Symbol', 'Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "symbols_df['Timestamp'] = pd.to_datetime(symbols_df['Timestamp'], unit='ms')\n",
    "symbols_df.sort_values(by=['Symbol', 'Timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df['Date'] = df['Timestamp'].dt.date\n",
    "\n",
    "    df['ADV'] = df.groupby(['Symbol', 'Date'])['Volume'].transform('mean')\n",
    "\n",
    "    df['Typical Price'] = (df['High'] + df['Low'] + df['Close']) / 3\n",
    "    df['Cumulative Price * Volume'] = df['Typical Price'] * df['Volume']\n",
    "\n",
    "    df['Cum_Volume'] = df.groupby(['Symbol', 'Date'])['Volume'].cumsum()\n",
    "    df['Cum_Price_Volume'] = df.groupby(['Symbol', 'Date'])['Cumulative Price * Volume'].cumsum()\n",
    "    df['VWAP'] = df['Cum_Price_Volume'] / df['Cum_Volume']\n",
    "\n",
    "    df['Price Change'] = df.groupby(['Symbol', 'Date'])['Close'].diff()\n",
    "\n",
    "    def obv(group):\n",
    "        obv = (group['Volume'].where(group['Price Change'] > 0, -group['Volume'])\n",
    "               .where(group['Price Change'] != 0, 0).cumsum())\n",
    "        return obv\n",
    "\n",
    "    df['OBV'] = df.groupby(['Symbol', 'Date']).apply(obv, include_groups=False).reset_index(drop=True)\n",
    "\n",
    "    df.drop(columns=['Date', 'Typical Price', 'Cum_Volume', 'Cum_Price_Volume', 'Cumulative Price * Volume', 'Price Change'], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_df = volume_features(symbols_df)\n",
    "volume_df.to_csv(volume_df_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VWAP</th>\n",
       "      <th>OBV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000AIDOGEUSDT</td>\n",
       "      <td>2024-03-28 16:00:00</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.006093</td>\n",
       "      <td>0.005933</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>51224500.0</td>\n",
       "      <td>26869925.0</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>-51224500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000000AIDOGEUSDT</td>\n",
       "      <td>2024-03-28 17:00:00</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>20305900.0</td>\n",
       "      <td>26869925.0</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>-71530400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000000AIDOGEUSDT</td>\n",
       "      <td>2024-03-28 18:00:00</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>0.005966</td>\n",
       "      <td>14693700.0</td>\n",
       "      <td>26869925.0</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>-56836700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000000AIDOGEUSDT</td>\n",
       "      <td>2024-03-28 19:00:00</td>\n",
       "      <td>0.005966</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>17056200.0</td>\n",
       "      <td>26869925.0</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>-39780500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000000AIDOGEUSDT</td>\n",
       "      <td>2024-03-28 20:00:00</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.006033</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>24093500.0</td>\n",
       "      <td>26869925.0</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>-63874000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Symbol            Timestamp      Open      High       Low  \\\n",
       "0  10000000AIDOGEUSDT  2024-03-28 16:00:00  0.006066  0.006093  0.005933   \n",
       "1  10000000AIDOGEUSDT  2024-03-28 17:00:00  0.005960  0.005980  0.005906   \n",
       "2  10000000AIDOGEUSDT  2024-03-28 18:00:00  0.005940  0.005989  0.005927   \n",
       "3  10000000AIDOGEUSDT  2024-03-28 19:00:00  0.005966  0.006010  0.005945   \n",
       "4  10000000AIDOGEUSDT  2024-03-28 20:00:00  0.006003  0.006033  0.005968   \n",
       "\n",
       "      Close      Volume         ADV      VWAP         OBV  \n",
       "0  0.005960  51224500.0  26869925.0  0.005995 -51224500.0  \n",
       "1  0.005940  20305900.0  26869925.0  0.005980 -71530400.0  \n",
       "2  0.005966  14693700.0  26869925.0  0.005977 -56836700.0  \n",
       "3  0.006003  17056200.0  26869925.0  0.005978 -39780500.0  \n",
       "4  0.005983  24093500.0  26869925.0  0.005981 -63874000.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume_df = pd.read_csv(volume_df_filename)\n",
    "volume_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = volume_df[['ADV', 'VWAP', 'OBV']].to_numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "X = torch.tensor(normalized_features, dtype=torch.float32)\n",
    "\n",
    "batch_size = 2\n",
    "dataset = torch.utils.data.TensorDataset(X)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, feature_dim, output_dim, dropout_prob=0.2):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(128, feature_dim),\n",
    "        )\n",
    "\n",
    "        self.residual = nn.Linear(feature_dim, feature_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        residual_output = self.residual(x)\n",
    "\n",
    "        output = decoded + residual_output\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_latent(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(model, dataloader, epochs=50, lr=1e-3, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for _batch_idx, (data,) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            loss = criterion(outputs, data)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    print(\"Training Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, dataloader, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _batch_idx, (data,) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            latent = model.get_latent(data)\n",
    "            embeddings.append(latent.cpu())\n",
    "\n",
    "    embeddings = torch.vstack(embeddings)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "output_dim = 10\n",
    "\n",
    "model = Autoencoder(feature_dim=input_dim, output_dim=output_dim)\n",
    "\n",
    "train_autoencoder(model, dataloader, epochs=100, lr=1e-3, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = extract_embeddings(model, dataloader, device=device)\n",
    "\n",
    "np.save(emb_filename, embeddings.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant-ItqfnwFL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
